---
title: "Codes for prediction of Week 3"
output:
  html_document:
    df_print: paged
---

## Preamble


```{r setting packages}
libs <- c("ggplot2", "pracma", "brglm", "extRemes", "foreach", "doParallel", "gridExtra", "ismev")
sapply(libs,require,character.only = T, quietly = TRUE, warn.conflicts = FALSE)
```

```{r function files}
require(knitr,quietly=TRUE,warn.conflicts = FALSE)
knit("PredictEpidemicTools.Rmd",quiet = TRUE)
```

```{r parallel coding settings}
detectCores()
cl <- makeCluster(3) #set for 4 cores

registerDoParallel(cl)

getDoParWorkers()
```
## Section 3 : The ILI data

### Preparation of the data 

#### Import the data

```{r import and cleaning data}
incidences <- read.csv("ILIincidences1985-2019.csv", sep = ";")

incidences          <- incidences[!is.na(incidences$t_inc),]
incidences$t_inc    <-
as.numeric(levels(incidences$t_inc))[incidences$t_inc]
incidences$yearweek <- as.numeric(incidences$yearweek)
dates               <-
seq(as.Date("1985-01-01") , as.Date("2019-03-10"), by = "weeks")
incidences$dates    <- dates

incidences$weeknum <-
seq(1, length = length(incidences$year), by = 1)

incidences <-
incidences[-228, ] # Missing data on the original file.

```

#### Epidemic detection : Serfling method

```{r serfling}
debut_serfling <- c()
fin_serfling <- c()
seasonal.mean <- c()
up.serfling <- c()

for (s in 1986:2020) {
inc <- subset(incidences, season < s)
nb.epid <- length(unique(inc$season))
nonepid_inc <- subset(inc, t_inc < 279)
reg <- lm(
t_inc ~ weeknum + cos(2 * pi * weeknum / 52)
+ sin(2 * pi * weeknum / 52) + cos(4 * pi * weeknum / 52)
+ sin(4 * pi * weeknum / 52),
data = nonepid_inc
)

new <- data.frame(weeknum = inc$weeknum)
df.serfling <-
predict(reg,
newdata = new,
interval = "prediction",
level = 0.9)


df.serfling <- as.data.frame(df.serfling)
df.serfling$t_inc <- inc$t_inc

inc$serfling <- df.serfling$fit
inc$up_serfling <- df.serfling$upr
df.serfling$dates <- inc$dates


temp <- inc[inc$season == s - 1, ]
temp.week <- temp[temp$t_inc >= temp$up_serfling, ]$weeknum
if (length(temp.week) > 1) {
for (j in 1:(length(temp.week) - 1)) {
if ((temp.week[j] + 1 == temp.week[j + 1]) &
(j < length(temp.week))) {
debut_serfling <- c(debut_serfling, temp.week[j])

break
}
}
fin_serfling <-
c(fin_serfling, temp.week[max(which(diff(temp.week) == 1)) + 1])
}
seasonal.mean <-
c(seasonal.mean,  inc[inc$season == s - 1, ]$serfling)
up.serfling <-
c(up.serfling, inc[inc$season == s - 1, ]$up_serfling)
}


incidences$epid_serfling <- rep(0, length(incidences$t_inc))
for (i in 1:nb.epid) {
incidences[(incidences$weeknum >= debut_serfling[i]) &
(incidences$weeknum <= fin_serfling[i]), ]$epid_serfling <-
1
}
```

#### Add the variable t_inc_cent to the data = deseasonalized rates
```{r deseasonalized rates}
incidences$s.mean <- seasonal.mean
incidences$t_inc_cent <- incidences$t_inc - seasonal.mean
incidences$up.serfling <- up.serfling
```

### Figure 1

```{r fig1, }
x.plot <-
  ggplot(data = incidences, aes(x = incidences$dates, y = t_inc)) + geom_line(size = 0.3)
  x.plot <-
  x.plot + xlab("Years") + ylab("Incidence rates per 100,000")
  x.plot <-
  x.plot + scale_x_date(date_breaks = "2 years", date_labels = "%Y")
  x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 9),
  axis.text.x = element_text(size = 7),
  axis.text.y = element_text(size = 8)
  )
  x.plot
```

### 1985-2018 ILI data

Put the 2019 epidemic aside save it for a test case

```{r 1985-2018 data}
incidences2018 <- subset(x = incidences, subset = (season < 2019))
nb.epid <-
  length(unique(incidences2018$season)) ## number of epidemics between 1985 and 2019
```

### Lengths of Serfling epidemic periods

```{r serfling lenghts}
debut_serfling <- c()
fin_serfling <- c()

for (i in 1:nb.epid) {
  temp <-
    incidences2018[(incidences2018$epid_serfling == 1) &
                     (incidences2018$season == 1984 + i),]$weeknum
  debut_serfling <- c(debut_serfling, min(temp))
  fin_serfling <- c(fin_serfling, max(temp))
}
longest <- max(fin_serfling - debut_serfling) + 1
shortest <- min(fin_serfling - debut_serfling) + 1
```


### Dectection of epidemic with proposed method in the paper

#### Define epidemic threshold (=275)

```{r detect epidemics}
level_epid <- 0.35
thres_epid <-
  quantile(incidences[incidences$epid_serfling == 1,]$t_inc, probs = level_epid, na.rm = T)
```

#### Create a new data frame containing the epidemic periods

```{r dataframe with new epidemics}
d <- longest
epid_data_thres <-
  EpidemicDataFrame(data = incidences2018, d = d, thres = thres_epid)
```

#### Lengths of the epidemic periods

```{r lengths of epidemic}
l.epid <- c()

for (i in unique(epid_data_thres$season)) {
  l.epid <-
    c(l.epid, length(epid_data_thres[(epid_data_thres$season == i) &
                                       (!is.na(epid_data_thres$t_inc)),]$t_inc))
}

longest_thres <- max(l.epid)
shortest_thres <- min(l.epid)
```


#### Correcting the dataframe containing new epidemics
```{r correction dataframe of new epidemics}
d <- longest_thres
epid_data_thres <-
  EpidemicDataFrame(data = incidences2018, d = d, thres = thres_epid)
```

### Figure 2
#### Figure 2.a)
```{r Figure 2a)}
d1 <- 1
d2 <- longest
serf_epid_data <-
  EpidemicDataFrameSerfling(data = incidences2018, d1 = d1, d2 = d2)
df.x <- serf_epid_data
x.plot <- ggplot(data = df.x, aes(x = 1:d2, y = t_inc))
for (i in 1:nb.epid) {
  x.plot <-
    x.plot + geom_line(data = df.x[df.x$season == 1984 + i,], aes(x = weeks, y = t_inc), size =
                         0.3)
}
x.plot <- x.plot + scale_x_continuous(breaks = seq(1, d2, 1))
x.plot <-
  x.plot + xlab("Epidemic weeks") + ylab("Weekly incidence rate per 100,000")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 13),
  axis.text.x = element_text(size = 9),
  axis.text.y = element_text(size = 9)
)
x.plot
```

#### Figure 2.b)

```{r Figure 2.b)}
df.x <- subset(epid_data_thres, weeks < d + 1)
x.plot <- ggplot(data = df.x, aes(x = 1:d, y = t_inc))
for (i in 1:nb.epid) {
  x.plot <-
    x.plot + geom_line(data = df.x[df.x$season == 1984 + i,], aes(x = weeks, y = t_inc), size =
                         0.3)
}
x.plot <- x.plot + scale_x_continuous(breaks = seq(1, d, 1))
x.plot <-
  x.plot + xlab("Epidemic weeks") + ylab("Weekly incidence rate per 100,000")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 12),
  axis.text.x = element_text(size = 9),
  axis.text.y = element_text(size = 9)
)
x.plot
```

### Construction of the data frame with the threshold excesses of the first 3 weeks
#### Dataframe containing the first 3 weeks of the epidemics

```{r dataframe first 3 weeks}
d <- 3
epid_data <-
  EpidemicDataFrame(data = incidences2018, d = d, thres = thres_epid)
```

#### Define the GPD threshold 

```{r GPD thres}
level_gpd <- c(0.3, 0.3, 0.3)
thres_gpd <- rep(NA, 3)
for (i in 1:3) {
  thres_gpd[i] <-
    quantile(epid_data[epid_data$weeks == i,]$t_inc_cent, probs = level_gpd[i], na.rm = T)
}
```

#### Add to the dataframe the excesses for extreme epidemic
```{r Add excesses}
`%nin%` = Negate(`%in%`)

epid_data$excess <- rep(NA, length(epid_data$season))

for (j in unique(epid_data$season)) {
  temp <- epid_data[epid_data$season == j,]
  if (sum(temp$t_inc_cent > thres_gpd, na.rm = T) == 0) {
    epid_data[epid_data$season == j,]$excess <- rep(NA, d)
  }
  else {
    epid_data[epid_data$season == j,]$excess <-
      temp$t_inc_cent - thres_gpd
  }
}
```

#### Number of extreme epidemics
```{r nb of extreme epidemics}
nb.epid_extreme <- sum(!is.na(epid_data$excess))/3
nb.epid_extreme
```

## Section 5 

### Section 5.1 : Risks of extreme rates in the next year

#### Fit an exponential distribution 

```{r exponential fit}
univ.fit_exp <- list()
sigma_univ <- rep(0, d)
df.param0 <- c(NA, NA, NA)
for (i in 1:(d)) {
  week <-
    epid_data[(epid_data$weeks == i) &
                !is.na(epid_data$t_inc_cent),]$t_inc_cent
  univ.fit_exp[[i]] <-
    fevd(
      x = week,
      threshold = thres_gpd[i],
      type = "Exponential",
      method = "MLE"
    )
  sigma_univ[i] <- univ.fit_exp[[i]]$results$par[1]
  ci.univ.fit <-
    ci.fevd(univ.fit_exp[[i]], 0.05, type = 'parameter')
  df.param0 <- rbind(df.param0, ci.univ.fit)
}
df.param0 <- df.param0[-1, ]
```

#### Table 1
```{r table 1}
kable(df.param0)
```

#### LR tests for testing $\gamma=0$

```{r LR tests}
loglik_gpd <- rep(0, 3)
for (i in 1:(d)) {
  week <-
    epid_data[(epid_data$weeks == i) &
                !is.na(epid_data$t_inc_cent),]$t_inc_cent
  fit <- fevd(x = week,
                 threshold = thres_gpd[i],
                  type = "GP", method ='MLE')
  loglik_gpd[i] <- fit$results$value
}

pvalue <- rep(0, 3)
for (i in 1:d) {
  lr <- -2 * (loglik_gpd[i] - univ.fit_exp[[i]]$results$value)
  pvalue[i] <- 1 - pchisq(q = lr, df = 1)
}
```


#### Figure 3 : Exponential qqplots
##### Figure 3a)

```{r Figure 3a)}
week1 <-
  epid_data[(epid_data$weeks == 1) &
              !is.na(epid_data$t_inc_cent),]$t_inc_cent
obs1 <- week1[week1 > thres_gpd[1]] - thres_gpd[1]
theo1  <-
  qevd(
    p = ppoints(length(obs1)),
    scale = sigma_univ[1],
    threshold = 0,
    type = "Exponential"
  )

df_qq1 <- data.frame(Obs = sort(obs1), Theo = theo1)
qq.plot1 <-
  ggplot(data = df_qq1, aes(x = Obs, y = Theo)) + geom_point(shape = 1, size = 3)
qq.plot1 <-
  qq.plot1 + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot1 <- qq.plot1 + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 14),
  axis.text.x = element_text(size = 12),
  axis.text.y = element_text(size = 12)
)
qq.plot1  <-  qq.plot1 + xlim(0, 325) + ylim(0 , 325) + coord_fixed()
qq.plot1 <- qq.plot1 + xlab("Observed") + ylab("Theorical")
qq.plot1
```

##### Figure 3b)

```{r Figure 3b)}
week2 <-
  epid_data[(epid_data$weeks == 2) &
              !is.na(epid_data$t_inc_cent),]$t_inc_cent
obs2 <- week2[week2 > thres_gpd[2]] - thres_gpd[2]
theo2  <-
  qevd(
    p = ppoints(length(obs2)),
    scale = sigma_univ[2],
    threshold = 0,
    type = "Exponential"
  )

df_qq2 <- data.frame(Obs = sort(obs2), Theo = theo2)
qq.plot2 <-
  ggplot(data = df_qq2, aes(x = Obs, y = Theo)) + geom_point(shape = 1, size = 3)
qq.plot2 <-
  qq.plot2 + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot2 <- qq.plot2 + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 14),
  axis.text.x = element_text(size = 12),
  axis.text.y = element_text(size = 12)
)
qq.plot2  <-  qq.plot2 + xlim(0, 915) + ylim(0 , 915) + coord_fixed()
qq.plot2 <- qq.plot2 + xlab("Observed") + ylab("Theorical")
qq.plot2
```

##### Figure 3c)

```{r Figure 3c)}
week3 <-
  epid_data[(epid_data$weeks == 3) &
              !is.na(epid_data$t_inc_cent),]$t_inc_cent
obs3 <- week3[week3 > thres_gpd[3]] - thres_gpd[3]
theo3  <-
  qevd(
    p = ppoints(length(obs3)),
    scale = sigma_univ[3],
    threshold = 0,
    type = "Exponential"
  )

df_qq3 <- data.frame(Obs = sort(obs3), Theo = theo3)
qq.plot3 <-
  ggplot(data = df_qq3, aes(x = Obs, y = Theo)) + geom_point(shape = 1, size = 3)
qq.plot3 <-
  qq.plot3 + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot3 <- qq.plot3 + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 14),
  axis.text.x = element_text(size = 12),
  axis.text.y = element_text(size = 12)
)
qq.plot3  <-
  qq.plot3 + xlim(0, 1500) + ylim(0 , 1500) +  coord_fixed()
qq.plot3 <- qq.plot3 + xlab("Observed") + ylab("Theorical")
qq.plot3
```

### Table 2 a)
```{r table 2a}
### Week 3###
#One year - 10% #
n <- 1
alpha <- 0.1
p.u <- 24 / 34
R1.10 <-
  thres_gpd[3] + sigma_univ[3] * (log(p.u) - log(1 - (1 - alpha) ^ (1 / n)))
#One year - 1% #
n <- 1
alpha <- 0.01
p.u <- 24 / 34
R1.1 <-
  thres_gpd[3] + sigma_univ[3] * (log(p.u) - log(1 - (1 - alpha) ^ (1 / n)))

#10 years - 10% #
n <- 10
alpha <- 0.1
p.u <- 24 / 34
R10.10 <-
  thres_gpd[3] + sigma_univ[3] * (log(p.u) - log(1 - (1 - alpha) ^ (1 / n)))

#10 years - 1% #
n <- 10
alpha <- 0.01
p.u <- 24 / 34
R10.1 <-
  thres_gpd[3] + sigma_univ[3] * (log(p.u) - log(1 - (1 - alpha) ^ (1 / n)))

kable(data.frame(R1.10, R1.1, R10.10, R10.1))
```

## Section 5.2

### Standardize the excesses

```{r standardize the excesses}
epid_data$excess_stand <- rep(NA, length(epid_data$season))
for (i in 1:d) {
  epid_data[epid_data$weeks == i,]$excess_stand <-
    epid_data[epid_data$weeks == i,]$excess / sigma_univ[i]
}
```

### Consider only extreme epidemics

```{r extreme epidemics}
season_NA <-
  unique(subset(x = epid_data, is.na(epid_data$excess))$season)
epid_data_ssNA <- subset(x = epid_data, season %nin% season_NA)


excess_stand_matrix <-
  matrix(epid_data_ssNA$excess_stand,
         ncol = d,
         byrow = T)
```

### Model selection

#### Fit a MGPD Gumbel model 

```{r fit Gumbel}
alpha0 <- runif(d, 2.5, 5)
b0 <- runif(d - 1, -2.5, 2.5) # if beta1 is fixed to 0 beta2 and beta 3 are close to 0
beta1 <- 0

fitGumbelU_standard <-
  optim(
    par = c(alpha0, b0),
    fn = LLKGumbelMGPDstand_U,
    x = excess_stand_matrix,
    beta1 = beta1,
    lw = c(1.1,-5),
    up = c(15, 5),
    control = list(maxit = 1e4, reltol = 1e-10)
  )


AIC_Gumbel <-
  2 * length(fitGumbelU_standard$par) + 2 * fitGumbelU_standard$value
BIC_Gumbel <-
  log(dim(excess_stand_matrix)[1]) * length(fitGumbelU_standard$par) + 2 *
  fitGumbelU_standard$value
```

#### Fit a MGPD reverse Gumbel model 

Note that the reserve Gumbel model can be very instable but AIC and BIC are always much larger than the other two models
```{r fit rev Gumbel}
alpha0 <- runif(d, 1.2, 2)
b0 <- rep(0.1, 2)
beta1 <- 0

fitRevGumbelU_standard <-
  optim(
    par = c(alpha0, b0),
    fn = LLKRevGumbelMGPDstand_U,
    x = excess_stand_matrix,
    beta1 = beta1,
    lw = c(1e-12,-50),
    up = c(15, 50),
    control = list(maxit = 1e4, reltol = 1e-10)
  )

AIC_RevGumbel <- 2*length(fitRevGumbelU_standard$par)+2*fitRevGumbelU_standard$value
BIC_RevGumbel <- log(dim(excess_stand_matrix)[1])*length(fitRevGumbelU_standard$par)+2*fitRevGumbelU_standard$value
```


#### Fit a MGPD reverse Exponential model 

```{r fit rev Expo}
alpha0 <- runif(d, 0.2, 5)
b0 <- runif(d - 1, -2.5, 2.5)
beta1 <- 0

fitRevExpoU_standard <- optim(
  par = c(alpha0, b0),
  fn = LLKRevExpoMGPDstand_U,
  x = excess_stand_matrix,
  beta1 = beta1,
  lw = c(0.1,-3),
  up = c(10, 3),
  control = list(maxit = 1e4, reltol = 1e-10)
)

AIC_RevExpo <- 2*length(fitRevExpoU_standard$par)+2*fitRevExpoU_standard$value
BIC_RevExpo <- log(dim(excess_stand_matrix)[1])*length(fitRevExpoU_standard$par)+2*fitRevExpoU_standard$value
```


### Table 3 a)
```{r table 3a}
tab3 <- data.frame(matrix(c(AIC_Gumbel,BIC_Gumbel, AIC_RevGumbel, BIC_RevGumbel,AIC_RevExpo,   BIC_RevExpo), ncol = 3))
colnames(tab3) <- c('Gumbel', 'RevGumbel', 'RevExpo')
rownames(tab3) <- c('AIC', 'BIC')
kable(tab3)
```

Selected model = Gumbel model 

## Model simplification 

### $\beta$ fixed equal to 0

```{r fit a model M2 : all beta are fixed}
alpha0 <- fitGumbelU_standard$par[1:d]
beta <- rep(0, d)

fitGumbelU_standard_alpha <-
  optim(
    par = alpha0,
    fn = LLKGumbelMGPDstand_U_alpha,
    x = excess_stand_matrix,
    beta = beta,
    lw = c(1.1),
    up = c(Inf),
    control = list(maxit = 1e4, reltol = 1e-10)
  )

AIC_M2 <-
  2 * 5 + 2 * fitGumbelU_standard_alpha$value
BIC_M2 <-
  log(dim(excess_stand_matrix)[1]) * 5 +
  2 * fitGumbelU_standard_alpha$value

T <-
  -2 * (fitGumbelU_standard$value - fitGumbelU_standard_alpha$value)
LR_M2 <-
  pchisq(q = T,
         df = (5 - length(fitGumbelU_standard_alpha$par)),
         lower.tail = F)
```

### all $\alpha$ are equal

```{r fit a model M2 : all alpha are equal}
a0 <- mean(fitGumbelU_standard$par[1:3])
b0 <- fitGumbelU_standard$par[-(1:3)]
beta1 <- 0

fitGumbelU_standard_abeta <-
  optim(
    par = c(a0, b0),
    fn = LLKGumbelMGPDstand_U_abeta,
    x = excess_stand_matrix,
    beta1 = beta1,
    lw = c(1.1,-4),
    up = c(Inf, 4),
    control = list(maxit = 1e4, reltol = 1e-10)
  )


AIC_M3 <-
  2 * 5 + 2 * fitGumbelU_standard_abeta$value
BIC_M3 <-
  log(dim(excess_stand_matrix)[1]) * 5 +
  2 * fitGumbelU_standard_abeta$value

T <-
  -2 * (fitGumbelU_standard$value - fitGumbelU_standard_abeta$value)
LR_M3 <-
  pchisq(
    q = T,
    df = 5 - length(fitGumbelU_standard_abeta$par),
    lower.tail = F
  )
```


### $\beta$ fixed equal to 0 and all $\alpha$ equal

```{r beta fixed equal to 0 and all alpha equal}
 a0 <- mean(fitGumbelU_standard$par[1:3])
 beta <- rep(0, d)

 fitGumbelU_standard_a <- optimize(
   f = LLKGumbelMGPDstand_U_a,
   x = excess_stand_matrix,
   beta = beta,
   lw = c(1.1),
   up = c(Inf),
   interval = c(1.1, 10)
 )

 AIC_M4 <- 2 + 2 * fitGumbelU_standard_a$objective
 BIC_M4 <-
   log(dim(excess_stand_matrix)[1]) + 2 * fitGumbelU_standard_a$objective

 T <- -2 * (fitGumbelU_standard$value - fitGumbelU_standard_a$objective)
 LR_M4 <-
   pchisq(
     q = T,
     df = 5 - length(fitGumbelU_standard_a$par),
     lower.tail = F
   )
```

### Table 4 a)

```{r table 4a}
tab4 <- data.frame(matrix(c(AIC_Gumbel,AIC_M2,AIC_M3,AIC_M4,BIC_Gumbel, BIC_M2, BIC_M3,BIC_M4,NA,LR_M2, LR_M3, LR_M4), ncol = 3))
colnames(tab4) <- c('AIC', 'BIC', 'LR')
rownames(tab4) <- c('M1', 'M2', 'M3','M4')
kable(tab4)
```

Selected model : M1

### Table 5a) and Saving the parameters
```{r table 5a}
est.alpha_M1 <- fitGumbelU_standard$par[1:3]
est.beta_M1 <- c(0,fitGumbelU_standard$par[-(1:3)])
est.matrix_M1 <- rbind(est.alpha_M1, est.beta_M1)
write.csv(est.matrix_M1, file = "EstimatesParametersWeek3.csv")
kable(est.matrix_M1)
```

## Prediction of year 2019

### Estimation of the probability to be an extreme episode when x1 and x2 <0 : pu

```{r proba to be extreme}
den <- 0
num <- 0
for (i in 1985:2018) {
  temp <- epid_data[epid_data$season == i, ]
  den <-
    den + (temp[temp$weeks == 1,]$t_inc_cent < thres_gpd[1]) * (temp[temp$weeks == 2,]$t_inc_cent < thres_gpd[2])
  num <-
    num++(temp[temp$weeks == 1,]$t_inc_cent < thres_gpd[1]) * (temp[temp$weeks == 2,]$t_inc_cent < thres_gpd[2]) * (temp[temp$weeks == 3,]$t_inc_cent > thres_gpd[3])
}

proba_extreme <- num / den
write.csv(proba_extreme, file = "ProbaExtremeWeek3.csv")
```

### 2019 standardized excesses

```{r 2019 data}
incidences2019 <- subset(x = incidences, subset = (season == 2019))
epid_data2019 <-
  EpidemicDataFrame(data = incidences2019, d = 3, thres = thres_epid)

epid_data2019$excess <- rep(NA, length(epid_data2019$season))
epid_data2019$excess_stand <- rep(NA, length(epid_data2019$season))

for (j in unique(epid_data2019$season)) {
  temp <- epid_data2019[epid_data2019$season == j, ]
  if (sum(temp$t_inc_cent > thres_gpd, na.rm = T) == 0) {
    epid_data2019[epid_data2019$season == j, ]$excess <- rep(NA, d)
  }
  else {
    epid_data2019[epid_data2019$season == j, ]$excess <-
      temp$t_inc_cent - thres_gpd
  }
}

for (i in 1:d) {
  epid_data2019[epid_data2019$weeks == i, ]$excess_stand <-
    epid_data2019[epid_data2019$weeks == i, ]$excess / sigma_univ[i]
}
```

### Fix exceedances thresholds

```{r exceedance thresholds}
thres_cent <- max(epid_data[epid_data$weeks == 3, ]$t_inc_cent)
thres_stand <- (thres_cent-thres_gpd[3])/sigma_univ[3]
mult_pred <- c(0.5, 0.75,0.95,1,1.2)

thres_pred <- mult_pred*thres_stand
write.csv(thres_pred, file="FixedPredThresWeek3.csv")
```

### Table 6. a)

```{r table 6a)}
proba.pred <- matrix(0, nrow = 1, ncol = length(thres_pred))
proba.predict_GPD <- matrix(0, nrow = 1, ncol = length(thres_pred))
proba.predict_LOGIT <-
  matrix(0, nrow = 1, ncol = length(thres_pred))
topredict_2019 <-
  data.frame(week1 = epid_data2019[epid_data2019$weeks == 1,]$excess_stand,
             week2 = epid_data2019[epid_data2019$weeks == 2,]$excess_stand)

x12 <-
  2 * c(epid_data2019[epid_data2019$weeks == 1, ]$excess_stand, epid_data2019[epid_data2019$weeks == 2, ]$excess_stand)

for (i in 1:length(thres_pred)) {
  proba.predict_GPD[, i] <-
    excessprobGumbelU_3g12(
      v3 = thres_pred[i],
      x12 = x12,
      alpha = est.alpha_M1,
      beta = est.beta_M1
    ) * proba_extreme_3g12(x12 = x12)
  
  reg_2019 <-
    data.frame(
      week1 = epid_data_ssNA[epid_data_ssNA$weeks == 1, ]$excess_stand,
      week2 = epid_data_ssNA[epid_data_ssNA$weeks == 2, ]$excess_stand,
      P3 = as.numeric(epid_data_ssNA[epid_data_ssNA$weeks == 3, ]$excess_stand > thres_pred[i])
    )
  
  fit_2019 <- brglm(
    formula = P3 ~ week1 + week2,
    data = reg_2019,
    family = binomial,
    maxit = 100
  )
  
  proba.predict_LOGIT[, i] <-  predict(object = fit_2019,
                                       newdata = topredict_2019,
                                       type = "response")
}
proba.pred <- data.frame(matrix(c(thres_pred,
                    proba.predict_GPD,
                    proba.predict_LOGIT), ncol =  5, byrow = T))
colnames(proba.pred) <- c("0.5", "0.75", "0.95", "1", "1.2")
rownames(proba.pred) <- c("Threshold", "GP", "Logistic")
kable(proba.pred)
```


## Section 6.1 : leave-one-out cross-validation

### Data + GPD thresholds

```{r preparation}
epid_data_8519 <- rbind(epid_data, epid_data2019)
nb.epid <- length(unique(epid_data_8519$season))

level_gpd <- c(0.3, 0.3, 0.3)
thres_gpd <- rep(NA, 3)
for (i in 1:3) {
  thres_gpd[i] <-
    quantile(epid_data_8519[epid_data_8519$weeks == i, ]$t_inc_cent, probs = level_gpd[i], na.rm = T)
}
```

### Create train/tests data sets

```{r train test}
train_list <- list()
test_list <- list()

for (i in 1:nb.epid) {
  season_i <- unique(epid_data_8519$season)[i]
  index.remove <- which(epid_data_8519$season == season_i)
  epid_data_test <-
    subset(x = epid_data_8519, subset = season == season_i)
  epid_data_LOO <- epid_data_8519[-index.remove,]
 
  #Marginal Expo Fit
  sigma_univ <- rep(0, d)
  df.param_univ <- rep(NA, d)
  for (k in 1:d) {
    week <-
      epid_data_LOO[(epid_data_LOO$weeks == k) &
                      !is.na(epid_data_LOO$t_inc), ]$t_inc_cent
    univ.fit <-
      fevd(
        x = week,
        threshold = thres_gpd[k],
        type = "Exponential",
        method = "MLE"
      )
    sigma_univ[k] <- univ.fit$results$par[1]
  }
  #Create excesses
  `%nin%` = Negate(`%in%`)
  epid_data_LOO$excess <- rep(NA, length(epid_data_LOO$season))
  epid_data_LOO$excess_stand <-
    rep(NA, length(epid_data_LOO$season))
  for (j in epid_data_LOO$season) {
    temp <- epid_data_LOO[epid_data_LOO$season == j,]
    if (sum(temp$t_inc_cent > thres_gpd[1:d], na.rm = T) == 0) {
      epid_data_LOO[epid_data_LOO$season == j,]$excess <- rep(NA, d)
    }
    else {
      epid_data_LOO[epid_data_LOO$season == j,]$excess <-
        temp$t_inc_cent - thres_gpd[1:d]
    }
  }
  
  for (k in 1:d) {
    epid_data_LOO[epid_data_LOO$weeks == k,]$excess_stand <-
      epid_data_LOO[epid_data_LOO$weeks == k,]$excess / sigma_univ[k]
  }
  season_NA_LOO <-
    unique(subset(x = epid_data_LOO, is.na(epid_data_LOO$excess))$season)
  train_list[[i]] <-
    subset(x = epid_data_LOO, season %nin% season_NA_LOO)
  
  epid_data_test$excess <- rep(0, 3)
  epid_data_test$excess_stand <- rep(0, 3)
  for (k in 1:d) {
    epid_data_test[epid_data_test$weeks == k,]$excess <-
      epid_data_test[epid_data_test$weeks == k,]$t_inc_cent - thres_gpd[k]
    epid_data_test[epid_data_test$weeks == k,]$excess_stand <-
      epid_data_test[epid_data_test$weeks == k,]$excess / sigma_univ[k]
  }
  test_list[[i]] <- epid_data_test
}
```

### Leave-one-out fit 

```{r LOO fit}
LOO_fit_parallel <- foreach(
  i = 1:nb.epid,
  .packages = c("extRemes", "pracma"),
  .combine = rbind
) %dopar% {
  LOO_fit(i,train_list = train_list, thres_gpd = thres_gpd)
}

res.fitLOO_week3 <- data.frame(LOO_fit_parallel)
colnames(res.fitLOO_week3) <- c("Indice", "alpha1", "alpha2","alpha3", "beta1", "beta2", "beta3")

est.alpha_list <- list()
for (i in 1:nb.epid) {
  est.alpha_list [[i]] <-
    c(res.fitLOO_week3[i,]$alpha1,
      res.fitLOO_week3[i,]$alpha2,
      res.fitLOO_week3[i,]$alpha3)
}

est.beta_list <- list()
for (i in 1:nb.epid) {
  est.beta_list [[i]] <-
    c(res.fitLOO_week3[i,]$beta1,
      res.fitLOO_week3[i,]$beta2,
      res.fitLOO_week3[i,]$beta3)
}
```

### Leave-one-out prediction 

```{r LOO predict}

res_parallel <- foreach(
  i = 1:nb.epid,
  .packages = c("extRemes", "brglm", "pracma"),
  .combine = rbind
) %dopar% {
  pred_parallel(i, train_list = train_list, test_list = test_list)
}


res_week3_LOO <- data.frame(res_parallel)
colnames(res_week3_LOO) <-
  c(
    "Week3",
    "Predict_Gumbel_05",
    "Predict_Gumbel_075",
    "Predict_Gumbel_095",
    "Predict_Gumbel_1",
    "Predict_Gumbel_12",
    "Predict_Logit_05",
    "Predict_Logit_075",
    "Predict_Logit_095",
    "Predict_Logit_1",
    "Predict_Logit_12",
    "LLK"
  )

res_week3_LOO$season <- 1985:2019
```

## Brier plots (Figures 5a) and b)

### Threshold = 0.5 $\times$ max = 816 (Figure 5a))

```{r brierplot05}

res_week3_05 <-
  subset(res_week3_LOO,
         select = c(Week3, Predict_Gumbel_05, Predict_Logit_05))
res_week3_05$Outcome <-
  as.numeric(res_week3_05$Week3 > thres_pred[1])


x.plot <-
  ggplot(data = res_week3_05, aes(x = as.factor(Outcome), y = Predict_Gumbel_05))
x.plot <-
  x.plot  +  geom_point(shape = 1)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8),
  plot.title = element_text(size = 10)
)

y.plot <-
  ggplot(data = res_week3_05, aes(x = as.factor(Outcome), y = Predict_Logit_05))
y.plot <-
  y.plot +  geom_point(shape = 1)
y.plot <- y.plot + ggtitle("Logistic regression")
y.plot <-
  y.plot + xlab("Outcome") + ylab("Prediction probability")
y.plot <- y.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8),
  plot.title = element_text(size = 10)
)

z.plot <- grid.arrange(x.plot, y.plot, ncol = 2)
```

### Threshold = 0.75 $\times$ max = 1,224 (Figure 5b))

```{r brierplot075}

res_week3_075 <-
  subset(res_week3_LOO,
         select = c(Week3, Predict_Gumbel_075, Predict_Logit_075))
res_week3_075$Outcome <-
  as.numeric(res_week3_075$Week3 > thres_pred[2])


x.plot <-
  ggplot(data = res_week3_075, aes(x = as.factor(Outcome), y = Predict_Gumbel_075))
x.plot <-
  x.plot + geom_point(shape = 1)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8),
  plot.title = element_text(size = 10)
)
x.plot

y.plot <-
  ggplot(data = res_week3_075, aes(x = as.factor(Outcome), y = Predict_Logit_075))
y.plot <-
  y.plot +  geom_point(shape = 1)
y.plot <- y.plot + ggtitle("Logistic regression")
y.plot <-
  y.plot + xlab("Outcome") + ylab("Prediction probability")
y.plot <- y.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8),
  plot.title = element_text(size = 10)
)


z.plot <- grid.arrange(x.plot, y.plot, ncol = 2)
```

### Threshold = 0.95 $\times$ max = 1,551  (not shown)

```{r brierplot095}

res_week3_095 <-
  subset(res_week3_LOO,
         select = c(Week3, Predict_Gumbel_095, Predict_Logit_095))
res_week3_095$Outcome <-
  as.numeric(res_week3_095$Week3 > thres_pred[3])


x.plot <-
  ggplot(data = res_week3_095, aes(x = as.factor(Outcome), y = Predict_Gumbel_095))
x.plot <-
  x.plot + geom_point(shape = 1)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8),
  plot.title = element_text(size = 10)
)
x.plot

y.plot <-
  ggplot(data = res_week3_095, aes(x = as.factor(Outcome), y = Predict_Logit_095))
y.plot <-
  y.plot +  geom_point(shape = 1)
y.plot <- y.plot + ggtitle("Logistic regression")
y.plot <-
  y.plot + xlab("Outcome") + ylab("Prediction probability")
y.plot <- y.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8),
  plot.title = element_text(size = 10)
)


z.plot <- grid.arrange(x.plot, y.plot, ncol = 2)
```

### Threshold = 1 $\times$ max = 1,632  (not shown)

```{r brierplot1}

res_week3_1 <-
  subset(res_week3_LOO, select = c(Week3, Predict_Gumbel_1))
res_week3_1$Outcome <- as.numeric(res_week3_1$Week3 > thres_pred[4])


x.plot <-
  ggplot(data = res_week3_1, aes(x = as.factor(Outcome), y = Predict_Gumbel_1))
x.plot <-
  x.plot + geom_point(shape = 1)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8),
  plot.title = element_text(size = 10)
)
x.plot
```

### Threshold = 1.2 $\times$ max = 1,959  (not shown)

```{r brierplot12}

res_week3_12 <-
  subset(res_week3_LOO, select = c(Week3, Predict_Gumbel_12))
res_week3_12$Outcome <-
  as.numeric(res_week3_12$Week3 > thres_pred[5])


x.plot <-
  ggplot(data = res_week3_12, aes(x = as.factor(Outcome), y = Predict_Gumbel_12))
x.plot <-
  x.plot + geom_point(shape = 1)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8),
  plot.title = element_text(size = 10)
)
x.plot
```

### Table 7
```{r table 7}
## 0.5
p_05 <- mean(res_week3_05$Outcome)
brier_gumbel_05 <- 1 - mean((res_week3_05$Predict_Gumbel_05 - res_week3_05$Outcome) ^ 2) /
  (p_05 * (1 - p_05))
brier_logit_05 <-  1 - mean((res_week3_05$Predict_Logit_05 - res_week3_05$Outcome) ^ 2,
           na.rm = T) /(p_05 * (1 - p_05))

## 0.75
p_075 <- mean(res_week3_075$Outcome)
brier_gumbel_075 <-
  1 - mean((res_week3_075$Predict_Gumbel_075 - res_week3_075$Outcome) ^ 2) /
  (p_075 * (1 - p_075))
brier_logit_075 <-
  1 - mean((res_week3_075$Predict_Logit_075 - res_week3_075$Outcome) ^ 2,
           na.rm = T) /
  (p_075 * (1 - p_075))

##0.95  
p_095 <- mean(res_week3_095$Outcome)
brier_gumbel_095 <-
  1 - mean((res_week3_095$Predict_Gumbel_095 - res_week3_095$Outcome) ^ 2) /
  (p_095 * (1 - p_095))
brier_logit_095 <-
  1 - mean((res_week3_095$Predict_Logit_095 - res_week3_095$Outcome) ^ 2,
           na.rm = T) /
  (p_095 * (1 - p_095))

##1
p_1 <- mean(res_week3_1$Outcome)
brier_gumbel_1 <-
  1 - mean((res_week3_1$Predict_Gumbel_1 - res_week3_1$Outcome) ^ 2) /
  (p_1 * (1 - p_1))

##1.2
p_12 <- mean(res_week3_12$Outcome)
brier_gumbel_12 <-
  1 - mean((res_week3_12$Predict_Gumbel_12 - res_week3_12$Outcome) ^ 2) /
  (p_12 * (1 - p_12))

brier_score <- data.frame(matrix(c(0.5, 0.75, 0.95, 1, 1.2, brier_gumbel_05, brier_gumbel_075, brier_gumbel_095, brier_gumbel_1, brier_gumbel_12, brier_logit_05, brier_logit_075, brier_logit_095, NA, NA), byrow = T, ncol = 5))
rownames(brier_score) <- c("Multiple", "GP", "Logistic")
kable(brier_score)
```


## Section 5.3

### Figure 4

```{r prepare dataframe for graph}
anomaly.df <- data.frame(season = unique(epid_data_8519$season))
anomaly.df$t_inc <- rep(0, nb.epid)
anomaly.df$t_inc_cent <- rep(0, nb.epid)
anomaly.df$excess <- rep(0, nb.epid)
anomaly.df$excess_stand <- rep(0, nb.epid)
for (i in 1:nb.epid) {
  toto <- unlist(test_list[[i]][3, 3:6])
  anomaly.df[i, ]$t_inc <- toto[1]
  anomaly.df$t_inc_cent[i] <- toto[2]
  anomaly.df$excess[i] <- toto[3]
  anomaly.df$excess_stand[i] <- toto[4]
}

anomaly.df <- anomaly.df[(anomaly.df$season<2016)|(anomaly.df$season>2017),]
anomaly.df$LLK <- -log(res_week3_LOO[(res_week3_LOO$season<2016)|(res_week3_LOO$season>2017),]$LLK)


```


```{r simulations}
## Get simulations
simul.dataU_Gumbel <-
  read.csv("SimulatedDataWeek3.csv",
    row.names = 1
  )
nb.epid_simus <- dim(simul.dataU_Gumbel)[1] / (33*3)
d <- dim(simul.dataU_Gumbel)[2]
simul.dataU_Gumbel$season <- rep(1:nb.epid_simus, each = 3)

simulGumbel_W3 <- simul.dataU_Gumbel[simul.dataU_Gumbel$weeks == 3, ]
q99 <- quantile(simulGumbel_W3$excess, probs = 0.99)
index1 <- which(simulGumbel_W3$excess > q99-1e-3)
temp <- simulGumbel_W3[index1, ]
index2 <- which(temp[temp$weeks == 3,]$excess < q99+1e-3)
```

```{r add extreme}
extreme.point.season <- temp[index2[2], ]$season
extreme.point.df <-
  simul.dataU_Gumbel[simul.dataU_Gumbel$season == extreme.point.season,]
extreme.point.vec <- as.vector(extreme.point.df$excess)
LLK.extreme <-
  DensityGumbelMGPDstand_U(x = extreme.point.vec, alpha = est.alpha_M1, beta = est.beta_M1)
extreme.point.df$LLK <- -log(LLK.extreme)
```

```{r add abnormal}
abnormal.point.vec <-
  c(extreme.point.vec[1] * 2,
    extreme.point.vec[2] * 0.1,
    extreme.point.vec[3] * 2)
abnormal.point.df <-
  data.frame(season = rep(1, 3),
             weeks = 1:3,
             excess = abnormal.point.vec)

LLK.abnormal <-
  DensityGumbelMGPDstand_U(x = abnormal.point.vec, alpha = est.alpha_M1, beta = est.beta_M1)
abnormal.point.df$LLK <- -log(LLK.abnormal)
```

```{r swine}
swine.point.df <- data.frame(
  season = rep(2010, 3),
  weeks = 1:3,
  excess = anomaly.df[anomaly.df$season == 2010,]$excess_stand,
  LLK = anomaly.df[anomaly.df$season == 2010,]$LLK
)
```

```{r cut off}
res_week3_simus <-
  read.csv(file = "PredSimus_Week3.csv", row.names = 1)

LLKsimus <- -log(res_week3_simus$LLK)
levels.10 <- quantile(LLKsimus, probs = 0.9)
levels.5 <- quantile(LLKsimus, probs = 0.95)
levels.1 <- quantile(LLKsimus, probs = 0.99)
levels.01 <- quantile(LLKsimus, probs = 0.999)
```

```{r figure 4}
x.plot <-
  ggplot(data = anomaly.df, aes(x = c(1985:2015, 2018, 2019), y = LLK))
x.plot <-
  x.plot + geom_point(shape = 1)
x.plot <-
  x.plot + geom_point(data = extreme.point.df, aes(2001, LLK), shape = 15, size = 2)
x.plot <-
  x.plot + geom_point(data = abnormal.point.df, aes(2015, LLK), shape = 17, size = 2)
x.plot <-
  x.plot + geom_point(data = swine.point.df, aes(2010, LLK), shape = 19, size = 2)
x.plot <-
  x.plot + geom_hline(yintercept = levels.1,
                      linetype = 2,
                      color = "blue")
x.plot <-
  x.plot + geom_hline(yintercept = levels.01,
                      linetype = 3,
                      color = "blue")
x.plot <-
  x.plot + xlab("Season") + ylab("Negative log-likelihood")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 10),
  axis.text.x = element_text(size = 8),
  axis.text.y = element_text(size = 8)
)
x.plot
```





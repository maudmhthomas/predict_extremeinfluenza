---
title: "Codes for prediction of epidemic sizes"
output:
  html_document:
    df_print: paged
    fig_caption : yes
---

## Preamble
```{r options}
knitr::opts_chunk$set(warning = FALSE, message = FALSE,  fig.path = "figures/", fig.height=6.51,fig.width=8.49, dev='png', fig.process = function(filename) {
    new_filename <- stringr::str_remove(string = filename,
                                        pattern = "-1")
    fs::file_move(path = filename, new_path = new_filename)
    ifelse(fs::file_exists(new_filename), new_filename, filename)
  })
set.seed(29106799)
```

```{r setting packages}
libs <- c("ggplot2", "pracma", "glmnet", "extRemes", "foreach", "doParallel", "gridExtra", "pROC", "MLmetrics", "energy")
sapply(libs,require,character.only = T, quietly = TRUE, warn.conflicts = FALSE)
```

```{r function files}
require(knitr,quietly=TRUE,warn.conflicts = FALSE)
knit("PredictEpidemicTools.Rmd",quiet = TRUE)
```

```{r parallel coding settings}
detectCores()
cl <- makeCluster(35) #set to number of cores -1

registerDoParallel(cl)

getDoParWorkers()
```

## Section 2: The ILI data

### Preparation of the data 

#### Import the data

```{r import and cleaning data}
incidences <- read.csv("ILIincidences1985-2019.csv", sep = ";")

incidences          <- incidences[!is.na(incidences$t_inc),]
incidences$t_inc    <-
as.numeric(levels(incidences$t_inc))[incidences$t_inc]
incidences$yearweek <- as.numeric(incidences$yearweek)
dates               <-
seq(as.Date("1985-01-01") , as.Date("2019-03-10"), by = "weeks")
incidences$dates    <- dates

incidences$weeknum <-
seq(1, length = length(incidences$year), by = 1)

incidences <-
incidences[-228, ] # Missing data on the original file.
```

```{r sentinelles durations}
debut_sentinelles <- c()
fin_sentinelles <- c()

for (i in unique(incidences$season)) {
  temp <-
    incidences[(incidences$epid == 1) &
                     (incidences$season == i),]$weeknum
  debut_sentinelles <- c(debut_sentinelles, min(temp))
  fin_sentinelles <- c(fin_sentinelles, max(temp))
}

l.epid_serf <- fin_sentinelles - debut_sentinelles + 1
longest <- max(l.epid_serf)
shortest <- min(l.epid_serf)
```

#### 1985-2018 ILI data

Put the 2019 epidemic aside save it for a test case

```{r 1985-2018 data}
incidences2018 <- subset(x = incidences, subset = (season < 2019))
nb.epid <-
  length(unique(incidences2018$season)) ## number of epidemics between 1985 and 2019
```


#### Detection of epidemic with proposed method in the paper

##### Define epidemic threshold 

```{r detect epidemics}
level_epid <- 0.88
thres_epid <-
  quantile(incidences2018$t_inc, probs = level_epid, na.rm = T)
```

Threshold for epidemic definition = `r thres_epid`. 

##### Create a new data frame containing the epidemic periods

```{r dataframe with new epidemics}
d <- longest
epid_data_thres <-
  EpidemicDataFrame(data = incidences2018, d = d, thres = thres_epid)
```


##### Durations of the epidemic periods

```{r durations of epidemic}
l.epid <- c()

for (i in unique(epid_data_thres$season)) {
  l.epid <-
    c(l.epid, length(epid_data_thres[(epid_data_thres$season == i) &
                                       (!is.na(epid_data_thres$t_inc)),]$t_inc))
}

longest_thres <- max(l.epid)
shortest_thres <- min(l.epid)
```

```{r number of epidemics}
nb.epid <- length(l.epid)
```

The number of epidemics with new definition is `r nb.epid`. 

#### Construction of the data frame with the threshold excesses of the first 3 weeks
##### Dataframe containing the first 3 weeks of the epidemic and a dataframe with the two first weeks and the size of the epidemic 

```{r dataframe first 2 weeks and the size}
d <- longest_thres
epid_data_thres <-
  EpidemicDataFrame(data = incidences2018, d = d, thres = thres_epid)
epid_data_cum <- EpidemicDataFrame_cum(data = epid_data_thres)
epid_data <-
  EpidemicDataFrame(data = incidences2018, d = 3, thres = thres_epid)
```

#### Correlation plots for ILI rates and the size
```{r ACFSize}
acf.temp <- acf(x = epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,lag.max = 10, plot = F)
acf.size <- data.frame(lag = acf.temp$lag, acf = acf.temp$acf)
ciline <- qnorm((1 - 0.95)/2)/sqrt(length(epid_data_cum[epid_data_cum$weeks == 3,]$t_inc))

x.plot <- ggplot(data = acf.size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Autocorrelation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r ADCFSize}
adcf.temp <- adcf(x = epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,lag.range=1:10,nreps=200)
adcf.size <- data.frame(lag = adcf.temp$lag, acf = adcf.temp$adcf)
ciline_u <- adcf.temp$u[1]
ciline_l <- adcf.temp$l[1]


x.plot <- ggplot(data = adcf.size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Auto distance correlation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```



```{r CCFWeek1Size}
ccf.temp <- acf(x = epid_data_cum[epid_data_cum$weeks == 1,]$t_inc,y = epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,lag.max = 10, plot = F)
ccf.week1.Size <- data.frame(lag = ccf.temp$lag, acf = ccf.temp$acf)
ciline <- qnorm((1 - 0.95)/2)/sqrt(length(epid_data_cum[epid_data_cum$weeks == 3,]$t_inc))

x.plot <- ggplot(data = ccf.week1.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Crosscorrelation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CDCFWeek1Size}
cdcf.temp <- cdcf(x = epid_data_cum[epid_data_cum$weeks == 1,]$t_inc,y = epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,lag.range=1:10,nreps=200)
cdcf.week1.Size <- data.frame(lag = cdcf.temp$lag, acf = cdcf.temp$cdcf)
ciline_u <- cdcf.temp$u[1]
ciline_l <- cdcf.temp$l[1]

x.plot <- ggplot(data = cdcf.week1.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline_u, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = ciline_l, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Cross distance correlation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CCFWeek2Size}
ccf.temp <- acf(x = epid_data_cum[epid_data_cum$weeks == 2,]$t_inc,y = epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,lag.max = 10, plot = F)
ccf.week2.Size <- data.frame(lag = ccf.temp$lag, acf = ccf.temp$acf)
ciline <- qnorm((1 - 0.95)/2)/sqrt(length(epid_data_cum[epid_data_cum$weeks == 3,]$t_inc))

x.plot <- ggplot(data = ccf.week2.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Crosscorrelation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CDCFWeek2Size}
cdcf.temp <- cdcf(x = epid_data_cum[epid_data_cum$weeks == 2,]$t_inc,y = epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,lag.range=1:10,nreps=200)
cdcf.week2.Size <- data.frame(lag = cdcf.temp$lag, acf = cdcf.temp$cdcf)
ciline_u <- cdcf.temp$u[1]
ciline_l <- cdcf.temp$l[1]

x.plot <- ggplot(data = cdcf.week2.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline_u, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = ciline_l, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Cross distance correlation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CCFWeek3Size}
ccf.temp <- acf(x = epid_data[epid_data$weeks == 3,]$t_inc,y = epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,lag.max = 10, plot = F)
ccf.week3.Size <- data.frame(lag = ccf.temp$lag, acf = ccf.temp$acf)
ciline <- qnorm((1 - 0.95)/2)/sqrt(length(epid_data_cum[epid_data_cum$weeks == 3,]$t_inc))

x.plot <- ggplot(data = ccf.week3.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Crosscorrelation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CDCFWeek3Size}
cdcf.temp <- cdcf(x = epid_data[epid_data$weeks == 3,]$t_inc,y = epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,lag.range=1:10,nreps=200)
cdcf.week3.Size <- data.frame(lag = cdcf.temp$lag, acf = cdcf.temp$cdcf)
ciline_u <- cdcf.temp$u[1]
ciline_l <- cdcf.temp$l[1]

x.plot <- ggplot(data = cdcf.week3.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline_u, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = ciline_l, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Cross distance correlation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```


## Section 4 

### Section 4.1 : Risks of extreme rates in the next year

#### Define the GPD threshold

```{r GPD thres}
d <- 3
level_gpd <- c(0.9, 0.9, 0.6)
thres_gpd <- rep(NA, 3)
for (i in 1:2) {
  thres_gpd[i] <-
    quantile(incidences2018$t_inc, probs = level_gpd[i], na.rm = T)
}
thres_gpd[3]  <- quantile(epid_data_cum[epid_data_cum$weeks == 3,]$t_inc,
              probs = level_gpd[3])
thres_week3 <- thres_gpd[1]
```

The GPD threshold for Weeks 1 and 2 and the Size is defined as the `r level_gpd`-quantile of the data, that is `r thres_gpd`. 

#### Add to the dataframe the excesses for extreme epidemic
```{r Add excesses}
`%nin%` = Negate(`%in%`)

epid_data_cum$excess <- rep(NA, length(epid_data_cum$season))

for (j in epid_data_cum$season) {
  temp <- epid_data_cum[epid_data_cum$season == j,]
  if (sum(temp$t_inc> thres_gpd, na.rm = T) == 0) {
    epid_data_cum[epid_data_cum$season == j,]$excess <- rep(NA, d)
  }
  else {
    epid_data_cum[epid_data_cum$season == j,]$excess <-
      temp$t_inc - thres_gpd
  }
}

epid_data$excess <- rep(NA, length(epid_data$season))

for (j in epid_data$season) {
  temp <- epid_data[epid_data$season == j,]
  if (sum(temp$t_inc> c(thres_gpd[1:2],thres_week3), na.rm = T) == 0) {
    epid_data[epid_data$season == j,]$excess <- rep(NA, d)
  }
  else {
    epid_data[epid_data$season == j,]$excess <-
      temp$t_inc - thres_gpd
  }
}
```



#### Correlation plots for excesses

```{r ACFExcessSize}
excessSize <- epid_data_cum[(epid_data_cum$weeks == 3),]$excess
acf.temp <- acf(x = excessSize[!is.na(excessSize)],lag.max = 10, plot = F)
acf.excessSize <- data.frame(lag = acf.temp$lag, acf = acf.temp$acf)
ciline <- qnorm((1 - 0.95)/2)/sqrt(length(excessSize[!is.na(excessSize)]))

x.plot <- ggplot(data = acf.excessSize, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Autocorrelation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r ADCFExcessSize}
adcf.temp <- adcf(x = excessSize[!is.na(excessSize)],lag.range=1:10,nreps=200)
adcf.excessSize <- data.frame(lag = adcf.temp$lag, adcf = adcf.temp$adcf)
ciline_u <- adcf.temp$u[1]
ciline_l <- adcf.temp$l[1]

x.plot <- ggplot(data = adcf.excessSize, aes(x = lag , y = adcf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline_u, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = ciline_l, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Auto Distance Correlation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```



```{r CCFExcess1Size}
excess1 <- epid_data_cum[(epid_data_cum$weeks == 1),]$excess
ccf.temp <- acf(x = excess1[!is.na(excess1)],y = excessSize[!is.na(excessSize)],lag.max = 10, plot = F)
ccf.excess1.Size <- data.frame(lag = ccf.temp$lag, acf = ccf.temp$acf)
ciline <- qnorm((1 - 0.95)/2)/sqrt(length(excess1[!is.na(excess1)]))

x.plot <- ggplot(data = ccf.excess1.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Crosscorrelation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CDCFExcess1ExcessSize}
cdcf.temp <- cdcf(x = excess1[!is.na(excess1)],y = excessSize[!is.na(excessSize)],lag.range=1:10,nreps=200)
cdcf.excess1.Size <- data.frame(lag = cdcf.temp$lag, acf = cdcf.temp$cdcf)
ciline_u <- cdcf.temp$u[1]
ciline_l <- cdcf.temp$l[1]

x.plot <- ggplot(data = cdcf.excess1.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline_u, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = ciline_l, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Cross distance correlation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CCFExcess2Size}
excess2 <- epid_data_cum[(epid_data_cum$weeks == 2),]$excess
ccf.temp <- acf(x = excess2[!is.na(excess2)],y = excessSize[!is.na(excessSize)],lag.max = 10, plot = F)
ccf.excess2.Size <- data.frame(lag = ccf.temp$lag, acf = ccf.temp$acf)
ciline <- qnorm((1 - 0.95)/2)/sqrt(length(excess1[!is.na(excess1)]))

x.plot <- ggplot(data = ccf.excess2.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Crosscorrelation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CDCFExcess2ExcessSize}
cdcf.temp <- cdcf(x = excess2[!is.na(excess2)],y = excessSize[!is.na(excessSize)],lag.range=1:10,nreps=200)
cdcf.excess2.Size <- data.frame(lag = cdcf.temp$lag, acf = cdcf.temp$cdcf)
ciline_u <- cdcf.temp$u[1]
ciline_l <- cdcf.temp$l[1]

x.plot <- ggplot(data = cdcf.excess2.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline_u, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = ciline_l, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Cross distance correlation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CCFExcess3Size}
excess3 <- epid_data[(epid_data$weeks == 2),]$excess
ccf.temp <- acf(x = excess3[!is.na(excess3)],y = excessSize[!is.na(excessSize)],lag.max = 10, plot = F)
ccf.excess3.Size <- data.frame(lag = ccf.temp$lag, acf = ccf.temp$acf)
ciline <- qnorm((1 - 0.95)/2)/sqrt(length(excess1[!is.na(excess1)]))

x.plot <- ggplot(data = ccf.excess3.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = -ciline, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Crosscorrelation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```

```{r CDCFExcess3ExcessSize}
cdcf.temp <- cdcf(x = excess3[!is.na(excess3)],y = excessSize[!is.na(excessSize)],lag.range=1:10,nreps=200)
cdcf.excess3.Size <- data.frame(lag = cdcf.temp$lag, acf = cdcf.temp$cdcf)
ciline_u <- cdcf.temp$u[1]
ciline_l <- cdcf.temp$l[1]

x.plot <- ggplot(data = cdcf.excess3.Size, aes(x = lag , y = acf)) + geom_bar(stat = 'identity', width = 0.03)
x.plot <- x.plot + geom_hline(yintercept = ciline_u, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = ciline_l, color = "blue",linetype =2)
x.plot <- x.plot + geom_hline(yintercept = 0, size = 0.2)
x.plot <-
  x.plot + xlab("Lag") + ylab("Cross distance correlation")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + scale_x_continuous(breaks = seq(0, 10, 2)) +scale_y_continuous(breaks = seq(-1, 1, .2))
x.plot
```


#### Fit an exponential distribution 

```{r exponential fit}
d <- 3
univ.fit_exp <- list()
sigma_univ <- rep(0, d)
df.param0 <- c(NA, NA, NA)
for (i in 1:(d)) {
  week <-
    epid_data_cum[(epid_data_cum$weeks == i) &
                    !is.na(epid_data_cum$t_inc), ]$t_inc
  univ.fit_exp[[i]] <-
    fevd(
      x = week,
      threshold = thres_gpd[i],
      type = "Exponential",
      method = "MLE"
    )
  sigma_univ[i] <- univ.fit_exp[[i]]$results$par[1]
  ci.univ.fit <-
    ci.fevd(univ.fit_exp[[i]], 0.05, type = 'parameter')
  df.param0 <- rbind(df.param0, ci.univ.fit)
}
df.param0 <- df.param0[-1,]
```

#### Table 1 Size
```{r table 1}
rownames(df.param0) <- c("Week1", "Week2", "Size")
kable(df.param0)
```

#### LR tests for testing $\gamma=0$

```{r LR tests}
univ.fit_gpd <- list()
for (i in 1:d) {
  week <-
    epid_data_cum[(epid_data_cum$weeks == i) &
                    !is.na(epid_data_cum$t_inc), ]$t_inc
  univ.fit_gpd[[i]]<-   fevd(
      x = week,
      threshold = thres_gpd[i],
      type = "GP",
      method = "MLE"
    )
}

pvalue <- rep(0, 3)
for (i in 1:d) {
  lr <- lr.test(univ.fit_gpd[[i]],univ.fit_exp[[i]])
  pvalue[i] <- lr$p.value
}
```

The p-values of the LR tests for $\gamma = 0$ for Weeks 1 and 2 and the Size are equal to `r pvalue` respectively. 

#### Exponential qqplots (Supplementary material)

```{r ExpoQQplotSize}
week <-
  epid_data_cum[(epid_data_cum$weeks == 3) &
                  !is.na(epid_data_cum$t_inc), ]$t_inc
obs <- week[week > thres_gpd[3]] - thres_gpd[3]
theo  <-
  qevd(
    p = ppoints(length(obs)),
    scale = sigma_univ[3],
    threshold = 0,
    type = "Exponential"
  )

df_qq <- data.frame(Obs = sort(obs), Theo = theo)
qq.plot <-
  ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 1, size = 2)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
qq.plot  <-
  qq.plot + xlim(0, 5000) + ylim(0 , 5000) + coord_fixed()
qq.plot <- qq.plot + xlab("Observed") + ylab("Theorical")
qq.plot

```

#### Table 2 (Size)
```{r table 2}
nb.excess.Size <- length(obs)
p.u <- nb.excess.Size / nb.epid

#One year - 10% #
n <- 1
alpha <- 0.1
R1.10 <-
  thres_gpd[3] + sigma_univ[3] * (log(p.u) - log(1 - (1 - alpha) ^ (1 / n)))
#One year - 1% #
n <- 1
alpha <- 0.01
R1.1 <-
  thres_gpd[3] + sigma_univ[3] * (log(p.u) - log(1 - (1 - alpha) ^ (1 / n)))

#10 years - 10% #
n <- 10
alpha <- 0.1
R10.10 <-
  thres_gpd[3] + sigma_univ[3] * (log(p.u) - log(1 - (1 - alpha) ^ (1 / n)))

#10 years - 1% #
n <- 10
alpha <- 0.01
R10.1 <-
  thres_gpd[3] + sigma_univ[3] * (log(p.u) - log(1 - (1 - alpha) ^ (1 / n)))

risks <- data.frame(R1.10, R1.1, R10.10, R10.1)
rownames(risks) <- c("risks")
colnames(risks) <- c("1 year - 10%", "1 year - 1%", "10 years - 10%", "10 years - 1%")
kable(risks)
```

The estimate of $\widehat p_u$ is equal to `r p.u`. 

### Section 4.2

#### Standardize the excesses

```{r standardize the excesses}
epid_data_cum$excess_stand <- rep(NA, length(epid_data_cum$season))
for (i in 1:d) {
  epid_data_cum[epid_data_cum$weeks == i,]$excess_stand <-
    epid_data_cum[epid_data_cum$weeks == i,]$excess / sigma_univ[i]
}
```

#### Consider only extreme epidemics

```{r extreme epidemics}
season_NA <-
  unique(subset(x = epid_data_cum, is.na(epid_data_cum$excess))$season)
epid_data_ssNA <- subset(x = epid_data_cum, season %nin% season_NA)


excess_stand_matrix <-
  matrix(epid_data_ssNA$excess_stand,
         ncol = d,
         byrow = T)
```

```{r nb of extreme epidemics}
nb.epid_extreme <- sum(!is.na(epid_data_cum$excess))/3
```
The number of extreme epidemics is `r nb.epid_extreme`. 

#### Model selection
For each model, we do the optimisation 50 times and then choose the parameters of the iteration which has the smaller -log(LLK). Since it takes a lot of time, we save the results in the file. 

##### Fit a MGPD Gumbel model 

```{r iterations fit Gumbel}
#  nb.run <- 50
# fit.Gumbel_fun <- function(i) {
#    library('pracma')
# alpha0 <- runif(d, 1.2, 50)
# b0 <- runif(d - 1, -1, 1) # if beta1 is fixed to 0 beta2 and beta 3 are close to 0
# beta1 <- 0
# 
# fitGumbelU_standard <- optim(
#     par = c(alpha0, b0),
#     fn = LLKGumbelMGPDstand_U,
#     x = excess_stand_matrix,
#     beta1 = beta1,
#     lw = c(1.1,-2),
#     up = c(100, 2),
#     control = list(maxit = 1e7, reltol = 1e-15)
#   )
# 
#    return(
#      c(
#        fitGumbelU_standard$par[1:d],
#        fitGumbelU_standard$par[-(1:d)],
#        fitGumbelU_standard$value
#      )
# )
# }
# 
# 
#  x_gumbel <- foreach(i = 1:nb.run) %dopar%  fit.Gumbel_fun(i)
#  res.Gumbel  <-
#    matrix(unlist(x_gumbel),
#           nrow = nb.run,
#           ncol = 2 * d,
#           byrow = T)
# 
#  res.Gumbel <- as.data.frame(res.Gumbel)
#  colnames(res.Gumbel) <-
#    c("alpha1", "alpha2", "alpha3", "beta2", "beta3", "LLK")
#  bestGumbel <- which.min(res.Gumbel$LLK)
# 
# write.csv(res.Gumbel, file = 'res.GumbelFitSize.csv')
```

```{r charge file with iterations of Gumbel fits}
res.Gumbel <- read.csv(file = "res.GumbelFitSize.csv", header = T, sep =",")
res.Gumbel <- res.Gumbel[,-1]
bestGumbel <- which.min(res.Gumbel$LLK)

AIC_Gumbel <-
  2 * (dim(res.Gumbel)[2]-1) + 2 * res.Gumbel[bestGumbel, d + 3]
BIC_Gumbel <-
  log(dim(excess_stand_matrix)[1]) * (dim(res.Gumbel)[2]-1) + 2 *
  res.Gumbel[bestGumbel, d + 3]
```

##### Fit a MGPD reverse Gumbel model 

Note that the reserve Gumbel model can be very instable but AIC and BIC are always much larger than the other two models


```{r iterations fit rev Gumbel}
#  nb.run <- 50
# fit.RevGumbel_fun <- function(i) {
#   library('pracma')
# alpha0 <- runif(d, 1.2, 2)
# b0 <- rep(0.1, 2)
# beta1 <- 0
# 
# fitRevGumbelU_standard <-
#   optim(
#     par = c(alpha0, b0),
#     fn = LLKRevGumbelMGPDstand_U,
#     x = excess_stand_matrix,
#     beta1 = beta1,
#     lw = c(1e-12,-1),
#     up = c(100, 1),
#     control = list(maxit = 1e7, reltol = 1e-15)
#   )
# 
#   return(
#     c(
#       fitRevGumbelU_standard$par[1:d],
#       fitRevGumbelU_standard$par[-(1:d)],
#       fitRevGumbelU_standard$value
#     )
#   )
# }
# x_revgumbel <- foreach(i = 1:nb.run) %dopar%  fit.RevGumbel_fun(i)
# res.RevGumbel  <-
#   matrix(
#     unlist(x_revgumbel),
#     nrow = nb.run,
#     ncol = 2 * d,
#     byrow = T
#   )
# 
# res.RevGumbel <- as.data.frame(res.RevGumbel)
# colnames(res.RevGumbel) <-
#   c("alpha1", "alpha2", "alpha3", "beta2", "beta3", "LLK")
# 
# write.csv(res.RevGumbel, file = 'res.RevGumbelFitSize.csv')
```

```{r}
res.RevGumbel <- read.csv(file = "res.RevGumbelFitSize.csv", header = T, sep =",")
res.RevGumbel <- res.RevGumbel[,-1]
bestRevGumbel <- which.min(res.RevGumbel$LLK)
AIC_RevGumbel <-
  2 *(dim(res.RevGumbel)[2]-1) + 2 * res.RevGumbel[bestRevGumbel, d +
                                                     3]
BIC_RevGumbel <-
  log(dim(excess_stand_matrix)[1]) *(dim(res.RevGumbel)[2]-1)  + 2 *
  res.RevGumbel[bestRevGumbel, d + 3]
```


##### Fit a MGPD reverse Exponential model 



```{r iterations fit rev Expo}
#  nb.run <- 50
#  fit.RevExpo_fun <- function(i) {
#    library('pracma')
#   alpha0 <- runif(d, 0.2, 5)
# b0 <- runif(d - 1, -2.5, 2.5)
# beta1 <- 0
# 
# fitRevExpoU_standard <- optim(
#   par = c(alpha0, b0),
#   fn = LLKRevExpoMGPDstand_U,
#   x = excess_stand_matrix,
#   beta1 = beta1,
#   lw = c(0.1,-3),
#   up = c(100, 3),
#   control = list(maxit = 1e7, reltol = 1e-15)
# )
#    return(
#      c(
#       fitRevExpoU_standard$par[1:d],
#        fitRevExpoU_standard$par[-(1:d)],
#       fitRevExpoU_standard$value
#      )
#    )
#  }
# 
# x_revexpo <- foreach(i = 1:nb.run) %dopar%  fit.RevExpo_fun(i)
#  res.RevExpo <-
#    matrix(unlist(x_revexpo),
#           nrow = nb.run,
#           ncol = 2 * d,
#           byrow = T)
# 
#  res.RevExpo <- as.data.frame(res.RevExpo)
#  colnames(res.RevExpo) <-
#    c("alpha1", "alpha2", "alpha3", "beta2", "beta3", "LLK")
# 
# write.csv(res.RevExpo, file = 'res.RevExpoFitSize.csv')
```

```{r}
res.RevExpo <- read.csv(file = "res.RevExpoFitSize.csv", header = T, sep =",")
res.RevExpo <- res.RevExpo[,-1]
 bestRevExpo <- which.min(res.RevExpo$LLK)
 AIC_RevExpo <-
   2 * (dim(res.RevExpo)[2]-1)  + 2 * res.RevExpo[bestRevExpo, d + 3]
 BIC_RevExpo <-
   log(dim(excess_stand_matrix)[1]) * (dim(res.RevExpo)[2]-1)  + 2 *
   res.RevExpo[bestRevExpo, d + 3]
```


#### Table 3 b)
```{r table 3b}
tab3 <- data.frame(matrix(c(AIC_Gumbel,BIC_Gumbel, AIC_RevGumbel, BIC_RevGumbel,AIC_RevExpo,   BIC_RevExpo), ncol = 3))
colnames(tab3) <- c('Gumbel', 'RevGumbel', 'RevExpo')
rownames(tab3) <- c('AIC', 'BIC')
kable(tab3)
```

Selected model = Gumbel model 

```{r Gumbel saving parameters and llk}
est.alpha_M1 <- as.numeric(res.Gumbel[bestGumbel, 1:d])
est.beta_M1 <- c(0, as.numeric(res.Gumbel[bestGumbel, (d + 1):(d + 2)]))

LLKGumbel <- as.numeric(res.Gumbel[bestGumbel, d+3])
```
### Model simplification 

#### $\beta$ fixed equal to 0

```{r fit a model M2 : all beta are fixed}
alpha0 <- est.alpha_M1
beta <- rep(0, d)

fitGumbelU_standard_alpha <-
  optim(
    par = alpha0,
    fn = LLKGumbelMGPDstand_U_alpha,
    x = excess_stand_matrix,
    beta = beta,
    lw = c(1.1),
    up = c(Inf),
    control = list(maxit = 1e7, reltol = 1e-15)
  )

AIC_M2 <-
  2 * 5 + 2 * fitGumbelU_standard_alpha$value
BIC_M2 <-
  log(dim(excess_stand_matrix)[1]) * 5 +
  2 * fitGumbelU_standard_alpha$value

T <-
  -2 * (LLKGumbel - fitGumbelU_standard_alpha$value)
LR_M2 <-
  pchisq(q = T,
         df = (5 - length(fitGumbelU_standard_alpha$par)),
         lower.tail = F)
```

#### all $\alpha$ are equal

```{r fit a model M2 : all alpha are equal}
a0 <- mean(est.alpha_M1)
b0 <- est.beta_M1[-1]
beta1 <- 0

fitGumbelU_standard_abeta <-
  optim(
    par = c(a0, b0),
    fn = LLKGumbelMGPDstand_U_abeta,
    x = excess_stand_matrix,
    beta1 = beta1,
    lw = c(1.1,-4),
    up = c(Inf, 4),
    control = list(maxit = 1e7, reltol = 1e-15)
  )


AIC_M3 <-
  2 * 5 + 2 * fitGumbelU_standard_abeta$value
BIC_M3 <-
  log(dim(excess_stand_matrix)[1]) * 5 +
  2 * fitGumbelU_standard_abeta$value

T <-
  -2 * (LLKGumbel - fitGumbelU_standard_abeta$value)
LR_M3 <-
  pchisq(
    q = T,
    df = 5 - length(fitGumbelU_standard_abeta$par),
    lower.tail = F
  )
```


#### $\beta$ fixed equal to 0 and all $\alpha$ equal

```{r beta fixed equal to 0 and all alpha equal}
 a0 <- mean(est.alpha_M1)
 beta <- rep(0, d)

 fitGumbelU_standard_a <- optimize(
   f = LLKGumbelMGPDstand_U_a,
   x = excess_stand_matrix,
   beta = beta,
   lw = c(1.1),
   up = c(Inf),
   interval = c(1.1, 10)
 )

 AIC_M4 <- 2 + 2 * fitGumbelU_standard_a$objective
 BIC_M4 <-
   log(dim(excess_stand_matrix)[1]) + 2 * fitGumbelU_standard_a$objective

 T <- -2 * (LLKGumbel - fitGumbelU_standard_a$objective)
 LR_M4 <-
   pchisq(
     q = T,
     df = 5 - length(fitGumbelU_standard_a$par),
     lower.tail = F
   )
```

#### Table for model simplification (supplementary material)

```{r table model simp}
tab4 <- data.frame(matrix(c(AIC_Gumbel,AIC_M2,AIC_M3,AIC_M4,BIC_Gumbel, BIC_M2, BIC_M3,BIC_M4,NA,LR_M2, LR_M3, LR_M4), ncol = 3))
colnames(tab4) <- c('AIC', 'BIC', 'LR')
rownames(tab4) <- c('M1', 'M2', 'M3','M4')
kable(tab4, digits = 20)
```

Selected model : M1

#### Table : estimates of the parameters
```{r tab estimates parameters}
est.matrix_M1 <- rbind(est.alpha_M1, est.beta_M1)
write.csv(est.matrix_M1, file = "EstimatesParametersSize.csv")
est.M1 <- data.frame(est.matrix_M1)
rownames(est.M1) <- c("alpha", "beta")
colnames(est.M1) <- c("1", "2", "3")
kable(est.M1)
```

### Prediction of year 2019

#### Estimation of the probability to be an extreme episode when x1 and x2 <0 :

```{r proba to be extreme}
den <- 0
num <- 0
for (i in 1985:2018) {
  temp <- epid_data_cum[epid_data_cum$season == i, ]
  den <-
    den + (temp[temp$weeks == 1,]$t_inc < thres_gpd[1]) * (temp[temp$weeks == 2,]$t_inc < thres_gpd[2])
  num <-
    num + (temp[temp$weeks == 1,]$t_inc < thres_gpd[1]) * (temp[temp$weeks == 2,]$t_inc < thres_gpd[2]) * (temp[temp$weeks == 3,]$t_inc > thres_gpd[3])
}

proba_extreme <- num / den
write.csv(proba_extreme, file = "ProbaExtremeSize.csv")
```

#### 2019 standardized excesses

```{r 2019 data}
incidences2019 <- subset(x = incidences, subset = (season == 2019))
epid_data2019 <-
  EpidemicDataFrame(data = incidences2019, d = 3, thres = thres_epid)

epid_data_cum2019 <- EpidemicDataFrame_cum(data = epid_data2019)
`%nin%` = Negate(`%in%`)

epid_data_cum2019$excess <-
  rep(NA, length(epid_data_cum2019$season))
epid_data_cum2019$excess_stand <-
  rep(NA, length(epid_data_cum2019$season))


for (j in unique(epid_data_cum2019$season)) {
  temp <- epid_data_cum2019[epid_data2019$season == j, ]
  if (sum(temp$t_inc > thres_gpd, na.rm = T) == 0) {
    epid_data_cum2019[epid_data_cum2019$season == j, ]$excess <-
      rep(NA, d)
  }
  else {
    epid_data_cum2019[epid_data_cum2019$season == j, ]$excess <-
      temp$t_inc - thres_gpd
  }
}

for (i in 1:d) {
  epid_data_cum2019[epid_data_cum2019$weeks == i, ]$excess_stand <-
    epid_data_cum2019[epid_data_cum2019$weeks == i, ]$excess / sigma_univ[i]
}
```

#### Fix exceedances thresholds

We will estimate the probabilty that the epidemic size will exceed the following thresholds defined as multiple of the observed maximum of  ILI rates of the third weeks of all epidemics (which is equal to `r max(epid_data_cum[epid_data_cum$weeks == 3, ]$t_inc)`).

```{r exceedance thresholds}
thres <-
  max(epid_data_cum[epid_data_cum$weeks == 3,]$t_inc)
thres_stand <- (thres - thres_gpd[3]) / sigma_univ[3]
mult_pred <- c(0.5, 0.75, 0.95, 1, 1.2)

thres_pred <- mult_pred*thres_stand
write.csv(thres_pred, file="FixedPredThresSize.csv")

thres_max <- data.frame(t(mult_pred*thres))
colnames(thres_max) <- c("0.5", "0.75", "0.95", "1", "1.2")
rownames(thres_max) <- c( "thresholds")
kable(thres_max)
```

#### Table  4b)

```{r table 4b)}
proba.pred <- matrix(NA, nrow = 1, ncol = length(thres_pred))
proba.predict_GPD <- matrix(NA, nrow = 1, ncol = length(thres_pred))
proba.predict_LOGIT <-
  matrix(NA, nrow = 1, ncol = length(thres_pred))

topredict_2019 <-
  data.frame(week1 = epid_data_cum2019[epid_data_cum2019$weeks == 1,]$excess_stand,
             week2 = epid_data_cum2019[epid_data_cum2019$weeks == 2,]$excess_stand)

x12 <-
  2 * c(epid_data_cum2019[epid_data_cum2019$weeks == 1, ]$excess_stand, epid_data_cum2019[epid_data_cum2019$weeks == 2, ]$excess_stand)

for (i in 1:length(thres_pred)) {
  proba.predict_GPD[, i] <-
    excessprobGumbelU_3g12(
      v3 = thres_pred[i],
      x12 = x12,
      alpha = est.alpha_M1,
      beta = est.beta_M1
    ) * proba_extreme_3g12(x12 = x12)
  
}
 reg_2019 <-
    matrix(data = c(epid_data_ssNA[epid_data_ssNA$weeks == 1, ]$excess_stand,
       epid_data_ssNA[epid_data_ssNA$weeks == 2, ]$excess_stand),ncol = 2)
    
for (i in 1:2){

      response <- as.numeric(epid_data_ssNA[epid_data_ssNA$weeks == 3, ]$excess_stand > thres_pred[i])
    
    
  fit <- glmnet(x = reg_2019, y = response, family = "binomial", alpha = 0, lambda = 1)

  proba.predict_LOGIT[, i] <-  predict(object = fit,
                                       newx = matrix(x12, ncol =2),
                                       type = "response")
}
proba.pred <- data.frame(matrix(c(thres*mult_pred,
                    proba.predict_GPD,
                    proba.predict_LOGIT), ncol =  5, byrow = T))
colnames(proba.pred) <- c("0.5", "0.75", "0.95", "1", "1.2")
rownames(proba.pred) <- c("Threshold", "GP", "Logistic")
kable(proba.pred)
```


## Section 5.2 i) : leave-one-out cross-validation

### Data + GPD thresholds

```{r preparation}
epid_data_8519 <- rbind(epid_data_cum, epid_data_cum2019)
nb.epid <- length(unique(epid_data_8519$season))

level_gpd <- c(0.9, 0.9, 0.6)
thres_gpd <- rep(NA, 3)
for (i in 1:2) {
  thres_gpd[i] <-
    quantile(incidences$t_inc, probs = level_gpd[i], na.rm = T)
}
thres_gpd[3]  <- quantile(epid_data_8519[epid_data_8519$weeks == 3,]$t_inc,
              probs = level_gpd[3])
```
### Create train/tests data sets

```{r train test}
train_list <- list()
test_list <- list()

for (i in 1:nb.epid) {
  season_i <- unique(epid_data_8519$season)[i]
  index.remove <- which(epid_data_8519$season == season_i)
  epid_data_test <-
    subset(x = epid_data_8519, subset = season == season_i)
  epid_data_LOO <- epid_data_8519[-index.remove,]
 
  #Marginal Expo Fit
  sigma_univ <- rep(0, d)
  df.param_univ <- rep(NA, d)
  for (k in 1:d) {
    week <-
      epid_data_LOO[(epid_data_LOO$weeks == k) &
                      !is.na(epid_data_LOO$t_inc), ]$t_inc
    univ.fit <-
      fevd(
        x = week,
        threshold = thres_gpd[k],
        type = "Exponential",
        method = "MLE"
      )
    sigma_univ[k] <- univ.fit$results$par[1]
  }
  #Create excesses
  `%nin%` = Negate(`%in%`)
  epid_data_LOO$excess <- rep(NA, length(epid_data_LOO$season))
  epid_data_LOO$excess_stand <-
    rep(NA, length(epid_data_LOO$season))
  for (j in epid_data_LOO$season) {
    temp <- epid_data_LOO[epid_data_LOO$season == j,]
    if (sum(temp$t_inc > thres_gpd[1:d], na.rm = T) == 0) {
      epid_data_LOO[epid_data_LOO$season == j,]$excess <- rep(NA, d)
    }
    else {
      epid_data_LOO[epid_data_LOO$season == j,]$excess <-
        temp$t_inc - thres_gpd[1:d]
    }
  }
  
  for (k in 1:d) {
    epid_data_LOO[epid_data_LOO$weeks == k,]$excess_stand <-
      epid_data_LOO[epid_data_LOO$weeks == k,]$excess / sigma_univ[k]
  }
  season_NA_LOO <-
    unique(subset(x = epid_data_LOO, is.na(epid_data_LOO$excess))$season)
  train_list[[i]] <-
    subset(x = epid_data_LOO, season %nin% season_NA_LOO)
  
  epid_data_test$excess <- rep(0, 3)
  epid_data_test$excess_stand <- rep(0, 3)
  for (k in 1:d) {
    epid_data_test[epid_data_test$weeks == k,]$excess <-
      epid_data_test[epid_data_test$weeks == k,]$t_inc - thres_gpd[k]
    epid_data_test[epid_data_test$weeks == k,]$excess_stand <-
      epid_data_test[epid_data_test$weeks == k,]$excess / sigma_univ[k]
  }
  test_list[[i]] <- epid_data_test
}
```

### Leave-one-out fit 

```{r LOO fit}
LOO_fit_parallel <- foreach(
  i = 1:nb.epid,
  .packages = c("extRemes", "pracma"),
  .combine = rbind
) %dopar% {
  LOO_fit(i,train_list = train_list, thres_gpd = thres_gpd)
}

res.fitLOO_Size <- data.frame(LOO_fit_parallel)
colnames(res.fitLOO_Size) <- c("Indice", "alpha1", "alpha2","alpha3", "beta1", "beta2", "beta3")

est.alpha_list <- list()
for (i in 1:nb.epid) {
  est.alpha_list [[i]] <-
    c(res.fitLOO_Size[i,]$alpha1,
      res.fitLOO_Size[i,]$alpha2,
      res.fitLOO_Size[i,]$alpha3)
}

est.beta_list <- list()
for (i in 1:nb.epid) {
  est.beta_list [[i]] <-
    c(res.fitLOO_Size[i,]$beta1,
      res.fitLOO_Size[i,]$beta2,
      res.fitLOO_Size[i,]$beta3)
}
```

### Leave-one-out prediction 

```{r LOO predict}

res_parallel_GPD <- foreach(
  i = 1:nb.epid,
  .packages = c("extRemes", "pracma"),
  .combine = rbind
) %dopar% {
  pred_parallel_GPD(i, train_list = train_list, test_list = test_list, thres_pred = thres_pred)
}


res_Size_LOO_GPD <- data.frame(res_parallel_GPD)
colnames(res_Size_LOO_GPD) <-
  c(
    "Size",
    "Predict_Gumbel_05",
    "Predict_Gumbel_075",
    "Predict_Gumbel_095",
    "Predict_Gumbel_1",
    "Predict_Gumbel_12",
    "LLK"
  )

res_Size_LOO_GPD$season <- 1985:2019
```

```{r LOO predict LOGIT}
res_parallel_LOGIT<- foreach(
  i = 1:nb.epid,
  .packages = c("glmnet"),
  .combine = rbind
) %dopar% {
  pred_parallel_LOGIT(i, train_list = train_list, test_list = test_list, thres_pred = thres_pred)
}


res_Size_LOO_LOGIT <- data.frame(res_parallel_LOGIT)
colnames(res_Size_LOO_LOGIT) <-
  c(
    "Predict_Logit_05",
    "Predict_Logit_075",
    "Predict_Logit_095",
    "Predict_Logit_1",
    "Predict_Logit_12"
  )

res_Size_LOO <- cbind(res_Size_LOO_GPD, res_Size_LOO_LOGIT)
```

### Prediction probabilities plots (Figures 4c) and d))

#### Threshold = 0.5 $\times$ max = 864 (Figure 4c))

```{r BrierReal_Sum05}

res_Size_05 <-
  subset(res_Size_LOO,
         select = c(Size, Predict_Gumbel_05, Predict_Logit_05))
res_Size_05$Outcome <-
  as.numeric(res_Size_05$Size > thres_pred[1])


x.plot <-
  ggplot(data = res_Size_05, aes(x = as.factor(Outcome), y = Predict_Gumbel_05))
x.plot <-
  x.plot  +  geom_point(shape = 1, size = 3)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + ylim(0,1)

y.plot <-
  ggplot(data = res_Size_05, aes(x = as.factor(Outcome), y = Predict_Logit_05))
y.plot <-
  y.plot +  geom_point(shape = 1, size = 3)
y.plot <- y.plot + ggtitle("Logistic regression")
y.plot <-
  y.plot + xlab("Outcome") + ylab("Prediction probability")
y.plot <- y.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
y.plot <- y.plot + ylim(0,1)

z.plot <- grid.arrange(x.plot, y.plot, ncol = 2)
```

#### Threshold = 0.75 $\times$ max = 6,046 (Figure 4d))

```{r BrierReal_Sum075}

res_Size_075 <-
  subset(res_Size_LOO,
         select = c(Size, Predict_Gumbel_075, Predict_Logit_075))
res_Size_075$Outcome <-
  as.numeric(res_Size_075$Size > thres_pred[2])


x.plot <-
  ggplot(data = res_Size_075, aes(x = as.factor(Outcome), y = Predict_Gumbel_075))
x.plot <-
  x.plot + geom_point(shape = 1, size = 3)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + ylim(0,1)

y.plot <-
  ggplot(data = res_Size_075, aes(x = as.factor(Outcome), y = Predict_Logit_075))
y.plot <-
  y.plot +  geom_point(shape = 1, size = 3)
y.plot <- y.plot + ggtitle("Logistic regression")
y.plot <-
  y.plot + xlab("Outcome") + ylab("Prediction probability")
y.plot <- y.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
y.plot <- y.plot + ylim(0,1)


z.plot <- grid.arrange(x.plot, y.plot, ncol = 2)
```

#### Threshold = 0.95 $\times$ max = 7,657 (not shown)

```{r BrierReal_Sum095}

res_Size_095 <-
  subset(res_Size_LOO,
         select = c(Size, Predict_Gumbel_095, Predict_Logit_095))
res_Size_095$Outcome <-
  as.numeric(res_Size_095$Size > thres_pred[3])


x.plot <-
  ggplot(data = res_Size_095, aes(x = as.factor(Outcome), y = Predict_Gumbel_095))
x.plot <-
  x.plot + geom_point(shape = 1, size = 3)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + ylim(0,1)
x.plot
```

#### Threshold = 1 $\times$ max = 8,062 (not shown)

```{r BrierReal_Sum1}

res_Size_1 <-
  subset(res_Size_LOO, select = c(Size, Predict_Gumbel_1))
res_Size_1$Outcome <- as.numeric(res_Size_1$Size > thres_pred[4])


x.plot <-
  ggplot(data = res_Size_1, aes(x = as.factor(Outcome), y = Predict_Gumbel_1))
x.plot <-
  x.plot + geom_point(shape = 1, size = 3)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + ylim(0,1)
x.plot
```

#### Threshold = 1.2 $\times$ max = 9,674 (not shown)

```{r BrierReal_Sum12}

res_Size_12 <-
  subset(res_Size_LOO, select = c(Size, Predict_Gumbel_12))
res_Size_12$Outcome <-
  as.numeric(res_Size_12$Size > thres_pred[5])


x.plot <-
  ggplot(data = res_Size_12, aes(x = as.factor(Outcome), y = Predict_Gumbel_12))
x.plot <-
  x.plot + geom_point(shape = 3)
x.plot <- x.plot + ggtitle("GP prediction")
x.plot <-
  x.plot + xlab("Outcome") + ylab("Prediction probability")
x.plot <- x.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
x.plot <- x.plot + ylim(0,1)
x.plot
```

#### Table 6 (Size) - Standardized Brier scores
```{r table 8}
## 0.5
p_05 <- mean(res_Size_05$Outcome)
brier_gumbel_05 <- 1 - mean((res_Size_05$Predict_Gumbel_05 - res_Size_05$Outcome) ^ 2) /
  (p_05 * (1 - p_05))
brier_logit_05 <-  1 - mean((res_Size_05$Predict_Logit_05 - res_Size_05$Outcome) ^ 2,
           na.rm = T) /(p_05 * (1 - p_05))

## 0.75
p_075 <- mean(res_Size_075$Outcome)
brier_gumbel_075 <-
  1 - mean((res_Size_075$Predict_Gumbel_075 - res_Size_075$Outcome) ^ 2) /
  (p_075 * (1 - p_075))
brier_logit_075 <-
  1 - mean((res_Size_075$Predict_Logit_075 - res_Size_075$Outcome) ^ 2,
           na.rm = T) /
  (p_075 * (1 - p_075))

##0.95
p_095 <- mean(res_Size_095$Outcome)
brier_gumbel_095 <-
  1 - mean((res_Size_095$Predict_Gumbel_095 - res_Size_095$Outcome) ^ 2) /
  (p_095 * (1 - p_095))

##1
p_1 <- mean(res_Size_1$Outcome)
brier_gumbel_1 <-
  1 - mean((res_Size_1$Predict_Gumbel_1 - res_Size_1$Outcome) ^ 2) /
  (p_1 * (1 - p_1))

##1.2
p_12 <- mean(res_Size_12$Outcome)
brier_gumbel_12 <-
  1 - mean((res_Size_12$Predict_Gumbel_12 - res_Size_12$Outcome) ^ 2) /
  (p_12 * (1 - p_12))

brier_score <- data.frame(matrix(c( brier_gumbel_05, brier_gumbel_075, brier_gumbel_095, brier_gumbel_1, brier_gumbel_12, brier_logit_05, brier_logit_075,NA, NA, NA), byrow = T, ncol = 5))
rownames(brier_score) <- c( "GP", "Logistic")
colnames(brier_score) <- c(0.5, 0.75, 0.95, 1, 1.2)
kable(brier_score)
```


## ROC and AUC (not shown in the paper)

### Threshold = 0.5 $\times$ max = 4,031

```{r PRCReal_Size05}
dis.thres_LOGIT <- sort(res_Size_05$Predict_Logit_05, decreasing = TRUE)
pr.data_LOGIT <-
  data.frame(DisThres = dis.thres_LOGIT, Model = rep("Logistic", length(dis.thres_LOGIT)))
for (i in 1:length(dis.thres_LOGIT)) {
  pr.data_LOGIT$Precision[i] <- sum((res_Size_05$Outcome == 1) &
                                      (res_Size_05$Predict_Logit_05 > dis.thres_LOGIT[i]) , na.rm = T 
                                    ) / sum((res_Size_05$Predict_Logit_05 > dis.thres_LOGIT[i]), na.rm = T)
  pr.data_LOGIT$Recall[i] <- sum((res_Size_05$Outcome == 1) &
                                      (res_Size_05$Predict_Logit_05 > dis.thres_LOGIT[i]), na.rm = T 
                                    ) / sum( (res_Size_05$Outcome == 1))
}


dis.thres_MGPD <- sort(res_Size_05$Predict_Gumbel_05, decreasing = TRUE)
pr.data_MGPD <-
  data.frame(DisThres = c(dis.thres_MGPD),
             Model = rep("Gumbel", length(dis.thres_MGPD)))

for (i in 1:length(dis.thres_MGPD)) {
   pr.data_MGPD$Precision[i] <- sum((res_Size_05$Outcome == 1) &
                                      (res_Size_05$Predict_Gumbel_05 > dis.thres_MGPD[i]) , na.rm = T 
                                    ) / sum((res_Size_05$Predict_Gumbel_05 > dis.thres_MGPD[i]) )
  pr.data_MGPD$Recall[i] <- sum((res_Size_05$Outcome == 1) &
                                      (res_Size_05$Predict_Gumbel_05 > dis.thres_MGPD[i]), na.rm = T 
                                    ) / sum( (res_Size_05$Outcome == 1))
}



### Precision and recall ### 
pr.data <- rbind(pr.data_MGPD, pr.data_LOGIT)

y.plot <-
  ggplot(data = pr.data, aes(
    x = Recall,
    y = Precision,
    colour = Model,
    linetype = Model
  )) + geom_path()
y.plot <- y.plot + geom_hline(yintercept = sum( (res_Size_05$Outcome == 1))/length(res_Size_05$Outcome))

y.plot <- y.plot + xlim(c(0, 1)) + ylim(c(0, 1))
y.plot <- y.plot + scale_color_manual(values = c("blue", "red"))
y.plot <- y.plot + xlab("Recall") + ylab("Precision")
y.plot <- y.plot + theme(
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
y.plot


## AUC PR ###
auc_pr_GP_05 <- PRAUC(res_Size_05$Predict_Gumbel_05, res_Size_05$Outcome)
auc_pr_Logit_05 <- PRAUC(res_Size_05[!is.na(res_Size_05$Predict_Logit_05),]$Predict_Logit_05,res_Size_05[!is.na(res_Size_05$Predict_Logit_05),]$Outcome)



##  Average precision score ###
N <- length(pr.data_MGPD$Recall)
AP_GP_05 <- sum(pr.data_MGPD$Precision*(pr.data_MGPD$Recall - c(0,pr.data_MGPD$Recall[-N])), na.rm = T)
AP_LOGIT_05 <- sum(pr.data_LOGIT$Precision*(pr.data_LOGIT$Recall - c(0,pr.data_LOGIT$Recall[-N])), na.rm = T)
```




### Threshold = 0.75 $\times$ max = 6,046

```{r PRCReal_Size075}
dis.thres_LOGIT <- sort(res_Size_075$Predict_Logit_075, decreasing = TRUE)
pr.data_LOGIT <-
  data.frame(DisThres = dis.thres_LOGIT, Model = rep("Logistic", length(dis.thres_LOGIT)))
for (i in 1:length(dis.thres_LOGIT)) {
  pr.data_LOGIT$Precision[i] <- sum((res_Size_075$Outcome == 1) &
                                      (res_Size_075$Predict_Logit_075 > dis.thres_LOGIT[i]) , na.rm = T 
                                    ) / sum((res_Size_075$Predict_Logit_075 > dis.thres_LOGIT[i]), na.rm = T)
  pr.data_LOGIT$Recall[i] <- sum((res_Size_075$Outcome == 1) &
                                      (res_Size_075$Predict_Logit_075 > dis.thres_LOGIT[i]), na.rm = T 
                                    ) / sum( (res_Size_075$Outcome == 1))
}


dis.thres_MGPD <- sort(res_Size_075$Predict_Gumbel_075, decreasing = TRUE)

pr.data_MGPD <-
  data.frame(DisThres = c(dis.thres_MGPD),
             Model = rep("Gumbel", length(dis.thres_MGPD)))

for (i in 1:length(dis.thres_MGPD)) {

   pr.data_MGPD$Precision[i] <- sum((res_Size_075$Outcome == 1) &
                                      (res_Size_075$Predict_Gumbel_075 > dis.thres_MGPD[i]) , na.rm = T 
                                    ) / sum((res_Size_075$Predict_Gumbel_075 > dis.thres_MGPD[i]) )
  pr.data_MGPD$Recall[i] <- sum((res_Size_075$Outcome == 1) &
                                      (res_Size_075$Predict_Gumbel_075 > dis.thres_MGPD[i]), na.rm = T 
                                    ) / sum( (res_Size_075$Outcome == 1))
}


### Precision and recall ### 
pr.data <- rbind(pr.data_MGPD, pr.data_LOGIT)

y.plot <-
  ggplot(data = pr.data, aes(
    x = Recall,
    y = Precision,
    colour = Model,
    linetype = Model
  )) + geom_path()
y.plot <- y.plot + geom_hline(yintercept = sum( (res_Size_075$Outcome == 1))/length(res_Size_075$Outcome))

y.plot <- y.plot + xlim(c(0, 1)) + ylim(c(0, 1))
y.plot <- y.plot + scale_color_manual(values = c("blue", "red"))
y.plot <- y.plot + xlab("Recall") + ylab("Precision")
y.plot <- y.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
y.plot


## AUC PR ###
auc_pr_GP_075 <- PRAUC(res_Size_075$Predict_Gumbel_075, res_Size_075$Outcome)
auc_pr_Logit_075 <- PRAUC(res_Size_075[!is.na(res_Size_075$Predict_Logit_075),]$Predict_Logit_075,res_Size_075[!is.na(res_Size_075$Predict_Logit_075),]$Outcome)



##  Average precision score ###
N <- length(pr.data_MGPD$Recall)
AP_GP_075 <- sum(pr.data_MGPD$Precision*(pr.data_MGPD$Recall - c(0,pr.data_MGPD$Recall[-N])), na.rm = T)
AP_LOGIT_075 <- sum(pr.data_LOGIT$Precision*(pr.data_LOGIT$Recall - c(0,pr.data_LOGIT$Recall[-N])), na.rm = T)


```

### Threshold = 0.95 $\times$ max = 7,659

```{r PRCReal_Size095}
dis.thres_MGPD <- sort(res_Size_095$Predict_Gumbel_095, decreasing = TRUE)
pr.data_MGPD <-
  data.frame(DisThres = c(dis.thres_MGPD),
             Model = rep("Gumbel", length(dis.thres_MGPD)))

for (i in 1:length(dis.thres_MGPD)) {
  pr.data_MGPD$Precision[i] <- sum((res_Size_095$Outcome == 1) &
                                      (res_Size_095$Predict_Gumbel_095 > dis.thres_MGPD[i]) , na.rm = T 
                                    ) / sum((res_Size_095$Predict_Gumbel_095 > dis.thres_MGPD[i]) )
  pr.data_MGPD$Recall[i] <- sum((res_Size_095$Outcome == 1) &
                                      (res_Size_095$Predict_Gumbel_095 > dis.thres_MGPD[i]), na.rm = T 
                                    ) / sum( (res_Size_095$Outcome == 1))
}



### Precision and recall ### 
pr.data <- rbind(pr.data_MGPD)

y.plot <-
  ggplot(data = pr.data, aes(
    x = Recall,
    y = Precision,
    colour = Model,
    linetype = Model
  )) + geom_path()
y.plot <- y.plot + geom_hline(yintercept = sum( (res_Size_095$Outcome == 1))/length(res_Size_095$Outcome))

y.plot <- y.plot + xlim(c(0, 1)) + ylim(c(0, 1))
y.plot <- y.plot + scale_color_manual(values = c("blue"))
y.plot <- y.plot + xlab("Recall") + ylab("Precision")
y.plot <- y.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
y.plot


## AUC PR ###
auc_pr_GP_095 <- PRAUC(res_Size_095$Predict_Gumbel_095, res_Size_095$Outcome)



##  Average precision score ###
N <- length(pr.data_MGPD$Recall)
AP_GP_095 <- sum(pr.data_MGPD$Precision*(pr.data_MGPD$Recall - c(0,pr.data_MGPD$Recall[-N])), na.rm = T)

```

### Threshold = 1 $\times$ max = 8,062

```{r PRCReal_Size1}
dis.thres_MGPD <- sort(res_Size_1$Predict_Gumbel_1, decreasing = TRUE)
pr.data_MGPD <-
  data.frame(DisThres = c(dis.thres_MGPD),
             Model = rep("Gumbel", length(dis.thres_MGPD)))



for (i in 1:length(dis.thres_MGPD)) {
  
pr.data_MGPD$Precision[i] <- sum((res_Size_1$Outcome == 1) &
                                      (res_Size_1$Predict_Gumbel_1 > dis.thres_MGPD[i]) , na.rm = T 
                                    ) / sum((res_Size_1$Predict_Gumbel_1 > dis.thres_MGPD[i]) )
  pr.data_MGPD$Recall[i] <- sum((res_Size_1$Outcome == 1) &
                                      (res_Size_1$Predict_Gumbel_1 > dis.thres_MGPD[i]), na.rm = T 
                                    ) / sum( (res_Size_1$Outcome == 1))
}


### Precision and recall ### 
pr.data <- rbind(pr.data_MGPD)

y.plot <-
  ggplot(data = pr.data, aes(
    x = Recall,
    y = Precision,
    colour = Model,
    linetype = Model
  )) + geom_path()
y.plot <- y.plot + geom_hline(yintercept = sum( (res_Size_1$Outcome == 1))/length(res_Size_1$Outcome))

y.plot <- y.plot + xlim(c(0, 1)) + ylim(c(0, 1))
y.plot <- y.plot + scale_color_manual(values = c("blue"))
y.plot <- y.plot + xlab("Recall") + ylab("Precision")
y.plot <- y.plot + theme(
  panel.grid.minor = element_blank(),
  text = element_text(size = 16),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_text(size = 14),
  plot.title = element_text(size = 18)
)
y.plot


## AUC PR ###
auc_pr_GP_1 <- PRAUC(res_Size_1$Predict_Gumbel_1, res_Size_1$Outcome)



##  Average precision score ###
N <- length(pr.data_MGPD$Recall)
AP_GP_1 <- sum(pr.data_MGPD$Precision*(pr.data_MGPD$Recall - c(0,pr.data_MGPD$Recall[-N])), na.rm = T)


```


### Threshold = 1.2 $\times$ max = 9,674

Cannot be computed because there is no exceedance of this threshold. 

### Table of AUC for PRC ###

```{r auc for prc}
auc_prc <- data.frame(matrix(c(auc_pr_GP_05, auc_pr_GP_075, auc_pr_GP_095, auc_pr_GP_1, NA, auc_pr_Logit_05, auc_pr_Logit_075, NA, NA, NA), byrow = T, ncol = 5))
 rownames(auc_prc) <- c( "GP", "Logistic")
colnames(auc_prc) <- c(0.5, 0.75, 0.95, 1, 1.2)
kable(auc_prc) 
```


### Table of Average Precision Score ###

```{r aps}
aprec_score <- data.frame(matrix(c(AP_GP_05, AP_GP_075, AP_GP_095, AP_GP_1, NA, AP_LOGIT_05, AP_LOGIT_075, NA, NA, NA), byrow = T, ncol = 5)) 
rownames(aprec_score) <- c( "GP", "Logistic") 
colnames(aprec_score) <- c(0.5, 0.75, 0.95, 1, 1.2) 
kable(aprec_score)
```

